{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "N7xQLDOoLbF2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import inception_v3\n",
        "\n",
        "from scipy.linalg import sqrtm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation 용 코드 추가"
      ],
      "metadata": {
        "id": "PfC-FfA3Zgvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import sqrtm\n",
        "\n",
        "# Inception 모델 로드 및 설정\n",
        "inception_model = inception_v3(pretrained=True, transform_input=False)\n",
        "inception_model.fc = torch.nn.Identity()\n",
        "inception_model.to('cuda')\n",
        "inception_model.eval()\n",
        "\n",
        "def get_inception_features(model, images, device='cuda'):\n",
        "    with torch.no_grad():\n",
        "        if images.shape[1] == 1:  # grayscale 이미지인 경우 RGB로 변환\n",
        "            images = images.repeat(1, 3, 1, 1)\n",
        "        images = transforms.functional.resize(images, (299, 299), interpolation=transforms.InterpolationMode.BILINEAR)\n",
        "        return model(images.to(device)).detach().cpu()\n",
        "\n",
        "def calculate_fid(real_features, fake_features):\n",
        "    eps = 1e-6  # 작은 정규화 값\n",
        "    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False) + eps * np.eye(real_features.shape[1])\n",
        "    mu2, sigma2 = fake_features.mean(axis=0), np.cov(fake_features, rowvar=False) + eps * np.eye(fake_features.shape[1])\n",
        "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
        "    covmean = sqrtm(sigma1.dot(sigma2), disp=False)[0]\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real  # 복소수 부분 제거\n",
        "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    return fid\n",
        "\n",
        "\n",
        "def evaluate_generator(generator, batch_size=64):\n",
        "    z = torch.randn(batch_size, 100, 1, 1, device='cuda')\n",
        "    fake_images = generator(z)\n",
        "    real_images = next(iter(DataLoader(train_loader.dataset, batch_size=batch_size, shuffle=True)))[0].cuda()\n",
        "    fake_features = get_inception_features(inception_model, fake_images)\n",
        "    real_features = get_inception_features(inception_model, real_images)\n",
        "    fid = calculate_fid(real_features.numpy(), fake_features.numpy())\n",
        "    return fid\n"
      ],
      "metadata": {
        "id": "aWWrzjwvWKbW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NXvWEN3GLbF3"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # changed linear into conv net.\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img).view(-1, 1).squeeze(1)\n",
        "\n",
        "def train(generator, discriminator, optimizer_G, optimizer_D, iterations, train_loader, sample_interval=200):\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "    data_iter = iter(train_loader)\n",
        "\n",
        "    iter_idx = 0\n",
        "    while True:\n",
        "        if iter_idx >= iterations:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            imgs, _ = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(train_loader)\n",
        "            imgs, _ = next(data_iter)\n",
        "\n",
        "        real_imgs = imgs.cuda()\n",
        "        valid = torch.ones(imgs.size(0), device='cuda')\n",
        "        fake = torch.zeros(imgs.size(0), device='cuda')\n",
        "\n",
        "        z = torch.randn(imgs.size(0), 100, 1, 1).cuda()\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if iter_idx % sample_interval == 0:\n",
        "            fid = evaluate_generator(generator)\n",
        "            print(f'[{iter_idx}/{iterations}] D/G Loss: [{d_loss.item():.4f}/{g_loss.item():.4f}] FID: {fid:.4f}')\n",
        "            sample_images(generator, iter_idx)\n",
        "\n",
        "        iter_idx += 1\n",
        "\n",
        "\n",
        "\n",
        "def sample_images(generator, iter_idx):\n",
        "    z =  torch.randn(16, 100, 1, 1, device='cuda')\n",
        "    gen_imgs = generator(z)\n",
        "    gen_imgs = gen_imgs.cpu().detach().numpy()\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(4, 4)\n",
        "    cnt = 0\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axs[i, j].imshow(np.transpose(gen_imgs[cnt], (1, 2, 0)), interpolation='nearest')  # RGB\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "\n",
        "    os.makedirs('./images', exist_ok=True)\n",
        "    fig.savefig(f\"images/mnist_{iter_idx}.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaAWQLvOLbF3",
        "outputId": "04ff2908-5b38-4507-cbc9-c6570f38e55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # CIFAR-10: 3 channel image\n",
        "])\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "train_loader = DataLoader(\n",
        "    datasets.CIFAR10('.', train=True, download=True, transform=transform),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWf99wjrLbF3",
        "outputId": "538d1953-17fc-4c05-91b4-ce721d95fbf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/2000] D/G Loss: [0.7825/3.6324] FID: 484.5607\n",
            "[20/2000] D/G Loss: [0.0801/10.7605] FID: 475.4830\n",
            "[40/2000] D/G Loss: [0.0097/15.4286] FID: 629.2363\n",
            "[60/2000] D/G Loss: [0.0068/15.6788] FID: 583.0297\n",
            "[80/2000] D/G Loss: [0.0329/7.5312] FID: 466.3063\n",
            "[100/2000] D/G Loss: [0.0079/15.8792] FID: 548.4538\n",
            "[120/2000] D/G Loss: [0.2101/17.8916] FID: 570.2869\n",
            "[140/2000] D/G Loss: [0.0034/6.7351] FID: 476.2393\n",
            "[160/2000] D/G Loss: [0.0452/6.3870] FID: 475.8429\n",
            "[180/2000] D/G Loss: [0.0362/5.0300] FID: 418.3519\n",
            "[200/2000] D/G Loss: [0.2637/4.5651] FID: 367.2468\n",
            "[220/2000] D/G Loss: [0.2139/3.2045] FID: 333.8575\n",
            "[240/2000] D/G Loss: [0.2015/2.5921] FID: 289.5624\n",
            "[260/2000] D/G Loss: [0.2998/6.6934] FID: 342.5491\n",
            "[280/2000] D/G Loss: [0.4495/4.0105] FID: 314.0411\n",
            "[300/2000] D/G Loss: [0.2569/3.2950] FID: 301.4988\n",
            "[320/2000] D/G Loss: [0.2834/3.6892] FID: 321.7054\n",
            "[340/2000] D/G Loss: [0.2603/3.2369] FID: 355.9438\n",
            "[360/2000] D/G Loss: [0.2556/1.7421] FID: 325.2469\n",
            "[380/2000] D/G Loss: [0.1727/3.3501] FID: 351.2161\n",
            "[400/2000] D/G Loss: [0.2546/3.4761] FID: 332.0100\n",
            "[420/2000] D/G Loss: [0.2435/2.9802] FID: 299.9690\n",
            "[440/2000] D/G Loss: [0.4120/3.4098] FID: 328.9378\n",
            "[460/2000] D/G Loss: [0.3278/3.3587] FID: 384.3576\n",
            "[480/2000] D/G Loss: [0.3355/3.8383] FID: 343.6685\n",
            "[500/2000] D/G Loss: [0.2894/2.9140] FID: 347.9858\n",
            "[520/2000] D/G Loss: [0.2490/2.6886] FID: 325.3925\n",
            "[540/2000] D/G Loss: [0.4647/2.5599] FID: 314.5913\n",
            "[560/2000] D/G Loss: [0.4078/4.5734] FID: 307.0720\n",
            "[580/2000] D/G Loss: [0.3967/4.0382] FID: 322.8507\n",
            "[600/2000] D/G Loss: [0.3594/4.1383] FID: 292.2752\n",
            "[620/2000] D/G Loss: [0.4945/4.5612] FID: 301.7405\n",
            "[640/2000] D/G Loss: [0.2595/3.4428] FID: 280.0582\n",
            "[660/2000] D/G Loss: [0.3854/3.3478] FID: 301.8533\n",
            "[680/2000] D/G Loss: [0.4274/1.6912] FID: 302.0395\n",
            "[700/2000] D/G Loss: [0.3356/5.0487] FID: 303.0937\n",
            "[720/2000] D/G Loss: [0.2980/2.1287] FID: 284.4998\n",
            "[740/2000] D/G Loss: [0.2340/3.2588] FID: 284.0988\n",
            "[760/2000] D/G Loss: [0.3245/3.1139] FID: 308.3894\n",
            "[780/2000] D/G Loss: [0.3344/3.3033] FID: 311.6818\n",
            "[800/2000] D/G Loss: [0.6872/6.2649] FID: 307.1881\n",
            "[820/2000] D/G Loss: [0.2245/3.5505] FID: 304.1997\n",
            "[840/2000] D/G Loss: [0.2128/3.0241] FID: 291.1253\n",
            "[860/2000] D/G Loss: [0.2189/2.9177] FID: 288.2899\n",
            "[880/2000] D/G Loss: [0.8125/0.7267] FID: 282.9494\n",
            "[900/2000] D/G Loss: [0.4264/2.3685] FID: 267.2756\n",
            "[920/2000] D/G Loss: [0.2593/3.8345] FID: 296.3915\n",
            "[940/2000] D/G Loss: [0.1743/3.5208] FID: 245.5163\n",
            "[960/2000] D/G Loss: [0.3255/3.1503] FID: 258.8593\n",
            "[980/2000] D/G Loss: [0.3517/4.0214] FID: 292.0860\n",
            "[1000/2000] D/G Loss: [0.3331/3.6113] FID: 282.3424\n",
            "[1020/2000] D/G Loss: [0.1744/3.0668] FID: 296.7710\n",
            "[1040/2000] D/G Loss: [0.5413/3.7311] FID: 292.5335\n",
            "[1060/2000] D/G Loss: [0.4578/1.9823] FID: 289.2283\n",
            "[1080/2000] D/G Loss: [0.1987/3.5402] FID: 287.3050\n",
            "[1100/2000] D/G Loss: [0.2097/2.9421] FID: 277.9259\n",
            "[1120/2000] D/G Loss: [0.2177/3.4161] FID: 267.1580\n",
            "[1140/2000] D/G Loss: [0.1430/3.1335] FID: 282.4418\n",
            "[1160/2000] D/G Loss: [0.0527/3.4842] FID: 262.4905\n",
            "[1180/2000] D/G Loss: [0.4801/4.0550] FID: 285.2398\n",
            "[1200/2000] D/G Loss: [0.4648/5.7731] FID: 260.7328\n",
            "[1220/2000] D/G Loss: [0.2733/2.4947] FID: 266.9119\n",
            "[1240/2000] D/G Loss: [0.1847/2.8131] FID: 296.2004\n",
            "[1260/2000] D/G Loss: [0.3795/4.1616] FID: 281.4417\n",
            "[1280/2000] D/G Loss: [0.2408/3.3618] FID: 262.3932\n",
            "[1300/2000] D/G Loss: [0.1784/3.2757] FID: 249.3825\n",
            "[1320/2000] D/G Loss: [0.3491/5.8836] FID: 283.5837\n",
            "[1340/2000] D/G Loss: [0.3447/2.4442] FID: 246.8587\n",
            "[1360/2000] D/G Loss: [0.2264/3.7196] FID: 274.3882\n",
            "[1380/2000] D/G Loss: [0.1739/3.3621] FID: 259.3507\n",
            "[1400/2000] D/G Loss: [0.2915/1.9817] FID: 265.9324\n",
            "[1420/2000] D/G Loss: [0.2515/3.8565] FID: 256.8536\n",
            "[1440/2000] D/G Loss: [0.0870/3.7261] FID: 269.3180\n",
            "[1460/2000] D/G Loss: [0.5301/4.5875] FID: 259.1446\n",
            "[1480/2000] D/G Loss: [0.3467/2.9166] FID: 243.9461\n",
            "[1500/2000] D/G Loss: [0.1618/3.7216] FID: 263.1075\n",
            "[1520/2000] D/G Loss: [0.3560/4.4456] FID: 246.5301\n",
            "[1540/2000] D/G Loss: [0.1631/2.6320] FID: 254.4628\n",
            "[1560/2000] D/G Loss: [0.2771/4.7200] FID: 256.6632\n",
            "[1580/2000] D/G Loss: [0.1099/3.2310] FID: 253.4942\n",
            "[1600/2000] D/G Loss: [0.1226/3.4598] FID: 246.9131\n",
            "[1620/2000] D/G Loss: [0.2067/4.9389] FID: 250.4859\n",
            "[1640/2000] D/G Loss: [0.1281/2.4631] FID: 252.9214\n",
            "[1660/2000] D/G Loss: [0.1154/3.5111] FID: 251.6356\n",
            "[1680/2000] D/G Loss: [0.0742/5.3336] FID: 241.8754\n",
            "[1700/2000] D/G Loss: [0.2472/2.9835] FID: 250.3069\n",
            "[1720/2000] D/G Loss: [0.3481/3.5020] FID: 280.1446\n",
            "[1740/2000] D/G Loss: [0.2613/2.7738] FID: 255.3916\n",
            "[1760/2000] D/G Loss: [0.3649/2.6053] FID: 270.3865\n",
            "[1780/2000] D/G Loss: [0.2934/2.6114] FID: 253.8275\n",
            "[1800/2000] D/G Loss: [0.3886/2.2815] FID: 238.1041\n",
            "[1820/2000] D/G Loss: [0.2362/3.1719] FID: 231.1499\n",
            "[1840/2000] D/G Loss: [0.1717/3.3518] FID: 248.4840\n",
            "[1860/2000] D/G Loss: [0.3069/4.1910] FID: 263.7036\n",
            "[1880/2000] D/G Loss: [0.2478/2.9808] FID: 250.4268\n",
            "[1900/2000] D/G Loss: [0.3600/1.4524] FID: 259.8507\n",
            "[1920/2000] D/G Loss: [0.3130/3.9673] FID: 231.5523\n",
            "[1940/2000] D/G Loss: [0.3366/3.6036] FID: 240.6986\n",
            "[1960/2000] D/G Loss: [0.2702/2.8210] FID: 246.9859\n",
            "[1980/2000] D/G Loss: [0.2034/2.3388] FID: 238.0342\n"
          ]
        }
      ],
      "source": [
        "# 생성자 및 판별자 초기화\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "generator.cuda()\n",
        "discriminator.cuda()\n",
        "\n",
        "# 손실 함수 및 최적화 기법 설정\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# 학습 수행\n",
        "iterations = 2000\n",
        "train(generator, discriminator, optimizer_G, optimizer_D, iterations, train_loader, sample_interval=20)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}